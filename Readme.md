# âš¡ Kafka Multi-Topic Multi-Consumer System (Go + Sarama)

A **production-ready Kafka architecture** built in **Go**, demonstrating a real-world **multi-topic, multi-consumer group setup** using the [Sarama](https://github.com/IBM/sarama) Kafka client.

---

## ğŸ“Š Architecture Overview

```
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  Producer  â”‚
             â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚      Kafka Topics    â”‚
       â”‚                      â”‚
       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
       â”‚  â”‚   orders      â”‚â—„â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚            â”‚
       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚            â”‚
       â”‚  â”‚   payments     â”‚â—„â”€â”¼â”€â”€â”€â”€â”€â”      â”‚
       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚     â”‚      â”‚
       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”‚      â”‚
       â”‚  â”‚ notifications â”‚â—„â”€â”€â”¼â”€â”€â”€â”€â”€â”˜      â”‚
       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
                  â–²                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ ConsumerGroup1â”‚         â”‚ ConsumerGroup2 â”‚
         â”‚ orders,       â”‚         â”‚ payments,      â”‚
         â”‚ payments      â”‚         â”‚ notifications  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  Kafka Concepts Simplified

### ğŸ”¹ Topics

Logical channels where events (messages) are published.
This project uses:

* `orders`
* `payments`
* `notifications`

Each topic has **2 partitions** for parallel consumption.

### ğŸ”¹ Partitions

Partitions let Kafka **scale horizontally** and **preserve order** within a partition.
We use **hash-based partitioning** by event ID â†’ ensures ordering per event.

### ğŸ”¹ Producer

* Sends structured JSON events into Kafka
* Uses **asynchronous delivery** (high throughput)
* Built with `sarama.AsyncProducer`

### ğŸ”¹ Consumer Groups

A **consumer group** is a set of consumers that share work.

| Group             | Topics Consumed             |
| ----------------- | --------------------------- |
| `service-group-1` | `orders`, `payments`        |
| `service-group-2` | `payments`, `notifications` |

Each group has independent offsets â†’ decoupled progress.

### ğŸ”¹ Offsets

Offsets = last-read position in a partition.
They enable replay, failure recovery, and consumer independence.

---

## ğŸ— Project Structure

```
kafka-system/
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ producer/           # Producer logic
â”‚   â”œâ”€â”€ consumer-group1/    # Group 1: orders + payments
â”‚   â””â”€â”€ consumer-group2/    # Group 2: payments + notifications
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ kafka/              # Shared Kafka setup
â”‚   â””â”€â”€ types/              # Event & Stats types
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ create-topics.sh    # Topic creation script
â”œâ”€â”€ docker-compose.yml      # Kafka + Zookeeper setup
â”œâ”€â”€ Makefile                # Developer shortcuts
â””â”€â”€ README.md               # You're here ğŸš€
```

---

## âš™ï¸ How to Run Locally

### âœ… 1. Start Kafka & Zookeeper

```bash
make start
```

Runs Kafka (`localhost:9092`) and Zookeeper (`localhost:2181`).

### âœ… 2. Create Topics

```bash
make setup
```

Creates: `orders`, `payments`, `notifications` with **2 partitions each**.

### âœ… 3. Run Services in Separate Terminals

**Terminal 1 â€“ Producer**

```bash
make producer
```

**Terminal 2 â€“ Consumer Group 1**

```bash
make consumer1
```

**Terminal 3 â€“ Consumer Group 2**

```bash
make consumer2
```

---

## ğŸ” Sample Event Output

```json
{
  "type": "order_created",
  "id": "evt-1721574564890993100",
  "data": "data-128",
  "timestamp": "2025-07-22T12:15:00Z"
}
```

---

## ğŸ“œ Makefile Commands

| Command          | Purpose                       |
| ---------------- | ----------------------------- |
| `make start`     | Start Kafka & Zookeeper       |
| `make setup`     | Create topics (`orders` etc.) |
| `make producer`  | Run producer                  |
| `make consumer1` | Run Consumer Group 1          |
| `make consumer2` | Run Consumer Group 2          |
| `make stop`      | Stop Kafka & Zookeeper        |
| `make logs`      | Show Kafka logs               |

---

## ğŸ“¦ Dependencies

* Go â‰¥ 1.18
* [Sarama](https://github.com/IBM/sarama) Kafka client
* Docker & Docker Compose

---

## ğŸ’¡ Real-World Use Cases

* Event-driven microservices â†’ orders, payments, notifications
* Log aggregation â†’ centralizing service logs
* ETL pipelines â†’ stream-transform-load architecture

---

## ğŸ”’ Graceful Shutdowns

Consumers trap `SIGINT` & `SIGTERM`, print summaries, and exit cleanly.

Example:

```
[orders][0] order_created: evt-1721574564890993100
[orders][1] order_updated: evt-1721574564890993115

Consumption Summary:
 orders[0]: 12
 orders[1]: 9
 orders TOTAL: 21
```

---

## ğŸ§ª Extensibility Ideas

* [ ] Add Prometheus metrics + Grafana dashboards
* [ ] REST API gateway for publishing events
* [ ] Schema Registry (Avro/Protobuf)
* [ ] Retry & Dead Letter Queues (DLQs)

---

## ğŸ§¼ Cleanup

```bash
docker-compose down        # Stop containers
docker-compose down -v     # Stop + remove volumes
```

---

## ğŸ¤ Credits

Built with â¤ï¸ using:

* [Apache Kafka](https://kafka.apache.org/)
* [Sarama](https://github.com/IBM/sarama)
* Go + Docker

---
